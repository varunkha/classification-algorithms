{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#All the imports & pyplot inline setting\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy.spatial import distance\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_file='project3_dataset2.txt'\n",
    "#n_file='project3_dataset1.txt'\n",
    "n_neighbours=5\n",
    "n_folds = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(n_file,header=None,delim_whitespace=True)\n",
    "shuffled_idx = np.random.permutation(df.index)\n",
    "df = df.reindex(shuffled_idx)\n",
    "data_truth = df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_label():\n",
    "    global data_distance\n",
    "    global test_truth\n",
    "    global data_label\n",
    "    idx = np.argpartition(data_distance, n_neighbours)[:,:n_neighbours]\n",
    "    for i in range(idx.shape[0]):\n",
    "        count0 = 0\n",
    "        distance0 = 0\n",
    "        count1 = 0\n",
    "        distance1 = 0\n",
    "        for k in range(idx.shape[1]):\n",
    "            if(train_truth[idx[i][k]]==0):\n",
    "                count0 += 1\n",
    "                distance0 += 1/data_distance[i][idx[i][k]]\n",
    "            elif(train_truth[idx[i][k]]==1):\n",
    "                count1 += 1\n",
    "                distance1 += 1/data_distance[i][idx[i][k]]\n",
    "        if(count0 > count1):\n",
    "            data_label[i] = 0\n",
    "        elif(count1 > count0):\n",
    "            data_label[i] = 1\n",
    "        elif(distance0 > distance1):\n",
    "            data_label[i] = 0\n",
    "        else:\n",
    "            data_label[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_distance(test,train):\n",
    "    global data_distance\n",
    "    for i in range(df.shape[1]-1):\n",
    "        if(df[i].dtype=='object'):\n",
    "            le = preprocessing.LabelEncoder()\n",
    "            le.fit(df[:][i])\n",
    "            l_test = le.transform(test[:][i])\n",
    "            l_test = l_test.reshape((l_test.shape[0], 1))\n",
    "            l_train = le.transform(train[:][i])\n",
    "            l_train = l_train.reshape((l_train.shape[0], 1))\n",
    "            dm = distance.cdist(l_test, l_train, lambda u, v: 0 if u==v else 1)\n",
    "        else:\n",
    "            l_test = test[:][i]\n",
    "            l_test = l_test.reshape((l_test.shape[0], 1))\n",
    "            l_train = train[:][i]\n",
    "            l_train = l_train.reshape((l_train.shape[0], 1))\n",
    "            dm = distance.cdist(l_test, l_train, 'euclidean')\n",
    "        dm = (dm-np.amin(dm))/(np.amax(dm)-np.amin(dm))\n",
    "        data_distance = np.add(data_distance,dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_measure(data_label,test_truth):\n",
    "    total = data_label.shape[0]\n",
    "    match = data_label[data_label.flatten()==test_truth.flatten()]\n",
    "    non_match = data_label[data_label.flatten()!=test_truth.flatten()]\n",
    "    pos = match[match==1].shape[0]\n",
    "    neg = match[match==0].shape[0]\n",
    "    false_pos = non_match[non_match==1].shape[0]\n",
    "    false_neg = non_match[non_match==0].shape[0]\n",
    "    cal_accuracy = (0.0 + pos + neg)/(0.0 + pos + neg + false_pos + false_neg)\n",
    "    cal_precision = (0.0 + pos)/(0.0 + pos + neg)\n",
    "    cal_recall = (0.0 + pos)/(0.0 + pos + false_neg)\n",
    "    denom = (0.0 + cal_precision + cal_recall)\n",
    "    if denom==0:\n",
    "        denom=1\n",
    "    cal_f_measure = (2.0*cal_precision*cal_recall)/denom\n",
    "    return (cal_accuracy,cal_precision,cal_recall,cal_f_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kFold 0:\n",
      "Accuracy: 0.608695652174\tPrecision: 0.178571428571\tRecall: 0.277777777778\tF-measure: 0.217391304348\n",
      "kFold 1:\n",
      "Accuracy: 0.586956521739\tPrecision: 0.333333333333\tRecall: 0.529411764706\tF-measure: 0.409090909091\n",
      "kFold 2:\n",
      "Accuracy: 0.804347826087\tPrecision: 0.0810810810811\tRecall: 0.333333333333\tF-measure: 0.130434782609\n",
      "kFold 3:\n",
      "Accuracy: 0.673913043478\tPrecision: 0.161290322581\tRecall: 0.333333333333\tF-measure: 0.217391304348\n",
      "kFold 4:\n",
      "Accuracy: 0.782608695652\tPrecision: 0.194444444444\tRecall: 0.4375\tF-measure: 0.269230769231\n",
      "kFold 5:\n",
      "Accuracy: 0.673913043478\tPrecision: 0.225806451613\tRecall: 0.4375\tF-measure: 0.297872340426\n",
      "kFold 6:\n",
      "Accuracy: 0.673913043478\tPrecision: 0.258064516129\tRecall: 0.444444444444\tF-measure: 0.326530612245\n",
      "kFold 7:\n",
      "Accuracy: 0.586956521739\tPrecision: 0.296296296296\tRecall: 0.380952380952\tF-measure: 0.333333333333\n",
      "kFold 8:\n",
      "Accuracy: 0.652173913043\tPrecision: 0.133333333333\tRecall: 0.266666666667\tF-measure: 0.177777777778\n",
      "kFold 9:\n",
      "Accuracy: 0.695652173913\tPrecision: 0.1875\tRecall: 0.4\tF-measure: 0.255319148936\n",
      "Average Accuracy: 0.673913043478\n",
      "Average Precision: 0.204972120738\n",
      "Average Recall: 0.384091970121\n",
      "Average F-Measure: 0.263437228234\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0.0\n",
    "precision = 0.0\n",
    "recall = 0.0\n",
    "f_measure = 0.0\n",
    "count=shuffled_idx.shape[0]//n_folds\n",
    "for i in range(n_folds):\n",
    "    test = df.iloc[count*i:count*(i+1)]\n",
    "    train = pd.concat([df.iloc[0:count*i],df.iloc[count*(i+1):]])\n",
    "    test_truth = data_truth[count*i:count*(i+1)]\n",
    "    train_truth = pd.concat([df.iloc[:,-1].iloc[0:count*i],df.iloc[:,-1].iloc[count*(i+1):]]).values\n",
    "    data_distance = np.zeros((test.shape[0],train.shape[0]))\n",
    "    data_label = np.zeros(test_truth.shape)\n",
    "    calculate_distance(test,train)\n",
    "    find_label()\n",
    "    current_accuracy,current_precision,current_recall,current_f_measure = calculate_measure(data_label,test_truth)\n",
    "    print 'kFold ' + str(i) + ':\\nAccuracy: ' + str(current_accuracy) + '\\tPrecision: ' + str(current_precision) + \\\n",
    "    '\\tRecall: ' + str(current_recall) + '\\tF-measure: ' + str(current_f_measure)\n",
    "    accuracy = accuracy + current_accuracy\n",
    "    precision = precision + current_precision\n",
    "    recall = recall + current_recall\n",
    "    f_measure = f_measure + current_f_measure\n",
    "print 'Average Accuracy: ' + str(accuracy/n_folds)\n",
    "print 'Average Precision: ' + str(precision/n_folds)\n",
    "print 'Average Recall: ' + str(recall/n_folds)\n",
    "print 'Average F-Measure: ' + str(f_measure/n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
